---
title: "Weakly Supervised Learning: Label Noise and Correction"
subtitle: "Applied Data Science Project 3"
author: "Marcus Loke"
date: "Spring 2022"
output:
  html_document: 
    theme: lumen
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
# Load required libraries
library(reticulate)
library(keras) # high-level neural networks API, written in Python and capable of running on top of TensorFlow
library(tensorflow)
library(nnet)
library(dplyr)
library(png)
library(glue)
library(stringr)
library(caret)

# Sets all random seeds needed to make TensorFlow code reproducible
set_random_seed(100)
```

# Load the datasets

For the project, we provide a training set with 50,000 images in the directory `../data/images/` with:

+ noisy labels for all images provided in `../data/noisy_labels.csv`;
+ clean labels for the first 10,000 images provided in `../data/clean_labels.csv`.

```{r}
# Load the images
n_img = 50000
n_noisy = 40000
n_clean_noisy = n_img - n_noisy
imgs = array(NA, c(n_img,32,32,3))

for (i in 1:n_img){
  img_fn = glue("../data/images/{str_pad(i, 5, pad='0')}.png")
  imgs[i,,,] = readPNG(img_fn) 
  i = i + 1
}

# Load the labels
clean_labels = as.matrix(read.csv("../data/clean_labels.csv", header=F))
noisy_labels = as.matrix(read.csv("../data/noisy_labels.csv", header=F))

# Combine into lists
cifar = list()
cifar$train$x = imgs
cifar$train$y = noisy_labels
cifar$test$x = imgs[1:10000,,,]
cifar$test$y = clean_labels
```

## Verify the data

For illustration, we present a small subset (of size 8) of the images with their clean and noisy labels in `clean_noisy_trainset`. You are encouraged to explore more characteristics of the label noises on the whole dataset.

```{r}
# The class label correspondence
classes = c('plane', 'car', 'bird', 'cat', 
            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

index = 1:8

# Print clean labels
par(mfrow = c(2,4), mar = rep(1, 4), oma = rep(0.2, 4))
cifar$train$x[index,,,] %>% 
  purrr::array_tree(1) %>%
  purrr::set_names(classes[clean_labels[index] + 1]) %>% 
  purrr::map(as.raster, max = 1) %>%
  purrr::iwalk(~{plot(.x); title(.y)})

# Print noisy labels
par(mfrow = c(2,4), mar = rep(1, 4), oma = rep(0.2, 4))
cifar$train$x[index,,,] %>% 
  purrr::array_tree(1) %>%
  purrr::set_names(classes[noisy_labels[index] + 1]) %>% 
  purrr::map(as.raster, max = 1) %>%
  purrr::iwalk(~{plot(.x); title(.y)})
```

# The predictive models

## Baseline model

We consider a baseline model directly on the noisy dataset without any label corrections. RGB histogram features are extracted to fit a logistic regression model.

```{r}
# RGB histogram data construction
no_bins = 6
bins = array(seq(0, 1, length.out=no_bins)) # the range of the rgb histogram
target_vec = array(NA, n_img)
feature_mtx = array(NA, c(n_img,3*(length(bins)-1)))
i = 0

for (i in 1:n_img) {
  # The target vector consists of noisy labels
  target_vec[i] = noisy_labels[i]
  
  # Use the number of pixels in each bin for all three channels as features
  feature1 = array(hist(imgs[i,,,1], breaks = bins, plot = F)$counts)
  feature2 = array(hist(imgs[i,,,2], breaks = bins, plot = F)$counts)
  feature3 = array(hist(imgs[i,,,3], breaks = bins, plot = F)$counts)
  
  # Concatenate three features
  feature_mtx[i,] = c(feature1, feature2, feature3)
  i = i + 1
}
```

```{r, message=FALSE, echo=TRUE, results='hide'}
# Train a multinomial logistic regression model with last 40,000 images
df_feature_mtx = cbind(as.data.frame(feature_mtx[10001:50000,]),
                       as.data.frame(target_vec[10001:50000])) %>%
  rename(target_vec = `target_vec[10001:50000]`)
clf = multinom(target_vec~., data = df_feature_mtx)

# Extract features for first 10,000 images (clean labels)
feature = array(NA, c(n_clean_noisy,3*(length(bins)-1)))
i = 0

for (i in 1:n_clean_noisy) {
  # Use the number of pixels in each bin for all three channels as features
  feature1 = array(hist(imgs[i,,,1], breaks = bins, plot = F)$counts)
  feature2 = array(hist(imgs[i,,,2], breaks = bins, plot = F)$counts)
  feature3 = array(hist(imgs[i,,,3], breaks = bins, plot = F)$counts)
  
  # Concatenate three features
  feature[i,] = c(feature1, feature2, feature3)
  i = i + 1
}
```

For the convenience of evaluation, we write the following function `baseline_model` that does the label prediction. For your predictive model, feel free to modify the function, but make sure the function takes RGB images of format with dimension $32 \times 32 \times 3$ as input, and returns labels as output.

```{r}
# This is the baseline predictive model that takes in an array of images and returns the label predictions
baseline_model <- function(images) {
  # Initialize vars
  feature = array(NA, c(nrow(images),3*(length(bins)-1)))
  i = 0
  
  for (i in 1:nrow(images)) {
    # Use the number of pixels in each bin for all three channels as features
    feature1 = array(hist(images[i,,,1], breaks = bins, plot = F)$counts)
    feature2 = array(hist(images[i,,,2], breaks = bins, plot = F)$counts)
    feature3 = array(hist(images[i,,,3], breaks = bins, plot = F)$counts)
  
    # Concatenate three features
    feature[i,] = c(feature1, feature2, feature3)
    i = i + 1
  }
  
  # Predict labels
  return(predict(clf, as.data.frame(feature)))
}
```

Also, for convenience of showing the results like precision, recall, F1 score, accuracy, etc., the following function is created to produce the classification report.

```{r}
# Function to produce classification report
# cm = confusion matrix; dp = no. of decimal places
class_report <- function(cm, dp=2) {
  ct <- sum(cm)
  cs <- colSums(cm)
  rs <- rowSums(cm)
  tp <- diag(cm)
  tn <- ct - (rs + cs - tp)
  fp <- rs - tp
  fn <- cs - tp
  pr <- tp / (tp + fp)
  re <- tp / (tp + fn)
  f1 <- 2 * pr * re / (pr + re)
  ac <- sum(tp) / ct
  list(summary=round(data.frame(tp, tn, fp, fn, precision=pr, recall=re, f1_score=f1, support=cs), dp),
       accuracy=round(ac, dp),
       support=ct)
}
```

Evaluate baseline model on the validation set, which contains the first 10,000 images with clean labels.

```{r}
# Predict on first 10,000 images and show results
valid = as.factor((as.data.frame(clean_labels))$V1)
pred = baseline_model(imgs[1:10000,,,])
class_report(table(pred, valid))
```

## Model 1: CNN

Here we build a convolutional neural network (CNN) that's trained on the last 40,000 images with noisy labels (i.e., image #10,001 to #50,000) and tested on the first 10,000 images with clean labels (i.e., image #1 to #10,000). This way of segmenting the data into train and validation sets are in the proportion of 80% to 20% respectively.

```{r, message=FALSE}
# Sequential = layer by layer building; not possible to share layers
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
                input_shape = c(32,32,3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

# Now flatten and apply neural net calculation
model %>%
  layer_flatten() %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

# Compile and train model
model %>% 
  compile(
    optimizer = "adam",
    loss = "sparse_categorical_crossentropy",
    metrics = "accuracy"
  )

# Fit the model
start_time = Sys.time()
results_train <- model %>% 
  fit(
    x = cifar$train$x[10001:50000,,,], y = cifar$train$y[10001:50000],
    epochs = 10,
    validation_data = unname(cifar$test),
    verbose = 2
  )
end_time = Sys.time()

# Evaluate model
plot(results_train)

# Time taken to train model
end_time - start_time
```

For the convenience of evaluation, we write the following function `cnn_model1` that does the label prediction. The function takes in RGB images of format with dimension $32 \times 32 \times 3$ as input, and returns labels as output.

```{r}
# This is the CNN predictive model that takes in an array of images and returns the label predictions
cnn_model1 <- function(images) {
  # Predict labels
  pred1 = model %>%
    predict(images) %>%
    k_argmax() %>%
    as.matrix() %>%
    as.factor()
  return(pred1)
}
```

Evaluate the CNN model on the validation set, which contains the first 10,000 images with clean labels.

```{r}
# Predict on first 10,000 images and show results
pred1 = cnn_model1(imgs[1:10000,,,])
class_report(table(pred1, valid))
evaluate(model, cifar$test$x, cifar$test$y, verbose = 0)
```

### 5-fold CV

To have a better estimation of the model performance on future unseen data, we performed 5-fold cross validation (CV) on the last 40,000 images and averaged the accuracy. We chose 5-fold CV and not a bigger k value because we did not want to overfit the model and we wanted a quicker run time. We also did not select too small a value for k due to the risk of the increase in bias. From the results below, the average accuracy from the 5-folds CV is 33%. Although there is a drop in accuracy from the same CNN model tested on the first 10,000 images, do note that the CV was trained and tested on the last 40,000 with noisy labels. Hence, this drop in accuracy is expected and can be improved with label correction (to be done next).

```{r, eval=FALSE}
# Create 5 folds that stores the indexes for each fold
set.seed(100)
folds = createFolds(cifar$train$x[10001:50000], k=5, list=TRUE, returnTrain=FALSE)

# Initialize vars
i = 1
acc_cv = NA

# Initlize CNN for CV
# Sequential = layer by layer building; not possible to share layers
model_cv <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
                input_shape = c(32,32,3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

# Now flatten and apply neural net calculation
model_cv %>%
  layer_flatten() %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

# Compile and train model
model_cv %>% 
  compile(
    optimizer = "adam",
    loss = "sparse_categorical_crossentropy",
    metrics = "accuracy"
  )

# Perform 5-fold CV on the last 40,000 images
for (i in 1:length(folds)) {
  # Train CNN model on all images except i-th fold
  model_cv %>%
    fit(
      x = cifar$train$x[unlist(folds[-i])+10000,,,], y = cifar$train$y[unlist(folds[-i])+10000],
      epochs = 10,
      validation_data = list(cifar$train$x[folds[[i]]+10000,,,],
                             cifar$train$y[folds[[i]]+10000]),
      #validation_data = unname(cifar$test),
      verbose = 2
    )
  
  # Predict on i-th fold
  valid_cv = as.factor(cifar$train$y[folds[[i]]+10000])
  pred_cv = model_cv %>%
    predict(cifar$train$x[folds[[i]]+10000,,,]) %>%
    k_argmax() %>%
    as.matrix() %>%
    as.factor()
  
  # Store accuracy
  acc_cv[i]= class_report(table(pred_cv, valid_cv))$accuracy
}

# Average accuracy across 5-folds
mean(acc_cv)
```

## Model 2: WSL with CNN

Here we approached the prediction modelling process in two main steps: First, we will train a CNN that does the label correction (i.e., mapping noisy labels to cleaned labels, conditioned on the input image). Then we use this CNN to correct the noisy labels to get cleaned ones, which will then be used to train our CNN in Model 1 for image classification.

+ **Step 1**: Train a label correction network on the first 7,000 images with clean labels (leave the remaining 3,000 images with clean labels for validation purposes in Step 2) and predict on the last 40,000 images to correct their labels.
+ **Step 2**: Once the labels have been corrected, we will re-train a new CNN (similar to Model 1) on the last 40,000 images and predict on the remaining 3,000 images for validation purposes. 

### Label correction network

First, we train a label correction network using CNN on the first 7,000 images with clean labels.

```{r}
# Sequential = layer by layer building; not possible to share layers
model_labcor <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
                input_shape = c(32,32,3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

# Now flatten and apply neural net calculation
model_labcor %>%
  layer_flatten() %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

# Compile and train model
model_labcor %>% 
  compile(
    optimizer = "adam",
    loss = "sparse_categorical_crossentropy",
    metrics = "accuracy"
  )

# Fit the model
start_time = Sys.time()
model_labcor %>% 
  fit(
    x = cifar$train$x[1:7000,,,], y = cifar$test$y[1:7000],
    epochs = 10,
    validation_data = list(cifar$test$x[7001:10000,,,],
                           cifar$test$y[7001:10000]),
    verbose = 2
  )
end_time = Sys.time()

# Time taken to train model
end_time - start_time
```

Predict on last 40,000 images to correct their labels.

```{r}
pred_labcor = model_labcor %>%
  predict(imgs[10001:50000,,,]) %>%
  k_argmax() %>%
  as.matrix() %>%
  as.factor()
```

### Model 2

Now that the labels have been corrected for the last 40,000 images, we will re-train a CNN on the 40,000 images and evaluate its performance on the remaining 3,000 images with clean labels.

```{r}
# Sequential = layer by layer building; not possible to share layers
model2 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
                input_shape = c(32,32,3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

# Now flatten and apply neural net calculation
model2 %>%
  layer_flatten() %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

# Compile and train model
model2 %>%
  compile(
    optimizer = "adam",
    loss = "sparse_categorical_crossentropy",
    metrics = "accuracy"
  )

# Fit the model
start_time = Sys.time()
model2 %>% 
  fit(
    x = cifar$train$x[10001:50000,,,], y = as.matrix(as.numeric(pred_labcor))-1,
    epochs = 10,
    validation_data = list(cifar$test$x[7001:10000,,,],
                           cifar$test$y[7001:10000]),
    verbose = 2
  )
end_time = Sys.time()

# Time taken to train model
end_time - start_time
```

For the convenience of evaluation, we write the following function `cnn_model2` that does the label prediction. The function takes in RGB images of format with dimension $32 \times 32 \times 3$ as input, and returns labels as output.

```{r}
# This is the CNN predictive model that takes in an array of images and returns the label predictions
cnn_model2 <- function(images) {
  # Predict labels
  pred2 = model2 %>%
    predict(images) %>%
    k_argmax() %>%
    as.matrix() %>%
    as.factor()
  return(pred2)
}
```

Evaluate the CNN model on the validation set, which contains the 3,000 images with clean labels.

```{r}
# Predict on the 3,000 images and show results
pred2 = cnn_model2(imgs[7001:10000,,,])
class_report(table(pred2, valid[7001:10000]))
```

# Evaluation

Evaluate on test set.

```{r}
cifar10 <- dataset_cifar10()

pred_test = cnn_model2(cifar10$test$x/255)
class_report(table(pred_test, as.factor(cifar10$test$y)))
```